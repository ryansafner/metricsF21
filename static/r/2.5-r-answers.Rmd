---
title: "2.5 — OLS: Precision and Diagnostics — R Practice"
author: "ECON 480 — Fall 2021"
date: "Tuesday, September 28, 2021"
output:
  html_document:
    df_print: paged
    toc: true 
    toc_depth: 3
    toc_float: true
    code_folding: show
    highlight: tango
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      fig.retina = 3,
                      fig.align = "center")
```

How did the results of the 2016 election in their district affect how often Members of Congress during the Trump Administration voted with the President? 

First, as always, load `tidyverse`!

## Question 1
Our [data](https://github.com/fivethirtyeight/data/tree/master/congress-trump-score) comes from fivethirtyeight's [Trump Congress tracker](https://projects.fivethirtyeight.com/congress-trump-score/). Fivethirtyeight has a great [public archive](https://data.fivethirtyeight.com/) of all of the data they use for their articles. I have saved a copy to this website so you can download it below. Download and import (`read_csv()`) the data into an object.

- [<i class="fas fa-table"></i> `congress-trump-score.csv`](/data/congress-trump-score.csv)

The variables that we care about are

| Variable | Description |
|----------|-------------|
| `congress` | Congressional session |
| `chamber` | Chamber of Congress |
| `last_name` | Member of Congress |
| `party` | Political Party |
| `state` | U.S. State |
| `district` | Congressional district |
| `agree_pct` | Proportion of votes that agree with President Trump (0-1) |
| `net_trump_vote` | District's margin of victory in 2016 election (positive is Trump win, negative is Clinton win) |

---

<!--ANSWER BELOW HERE-->

```{r}
library(tidyverse)
# again, my path (on website) may be different than yours
congress <- read_csv("../data/congress-trump-score.csv")
```

---

## Question 2
Look at the data with `glimpse()`. How many variables are there? How many observations?

---

<!--ANSWER BELOW HERE-->

```{r}
congress %>%
  glimpse()
```

---

## Question 3
`agree_pct` is oddly named, given that its values range from 0 to 1. Make a new variable (you can overwrite `agree_pct`) that is a true percentage, from 0 to 100, and use this going forward (it will make interpretation of our results easier).

---

<!--ANSWER BELOW HERE-->

```{r}
congress <- congress %>% # overwrite congress!
  mutate(agree_pct = agree_pct * 100)
```

---

## Question 4
Make a scatterplot of `agree_pct` on `net_trump_vote`. Add a regression line by adding an additional layer of `geom_smooth(method = "lm")`.

---

<!--ANSWER BELOW HERE-->

```{r}
scatter <- ggplot(data = congress)+
  aes(x = net_trump_vote, y = agree_pct)+
  geom_point()+
  geom_smooth(method = "lm")+
  theme_light()

scatter
```

---

## Question 5
Find the correlation between `agree_pct` and `net_trump_vote`. Hint: if using `tidyverse`, like calculating any statistic, we want the `summarize()` the data. 

---

<!--ANSWER BELOW HERE-->

```{r}
# using base R
cor(congress$net_trump_vote, congress$agree_pct)

# using tidyverse
congress %>%
  summarize(correlation = cor(net_trump_vote, agree_pct))
```

---

# Regression

## Question 6
We want to predict the following model:

$$\widehat{\text{agree_pct}}= \hat{\beta_0}+\hat{\beta_1} \,\text{net_trump_vote}$$
Run a regression and save it as an object. Then get a `summary()` of the object.

---

<!--ANSWER BELOW HERE-->

```{r}
reg <- lm(agree_pct ~ net_trump_vote, data = congress)

reg %>%
  summary()
```

---
 
### Part A
What is $\hat{\beta_0}$ for this model? What does it mean in the context of our question?

---

<!--ANSWER BELOW HERE-->

```{r}
# I just want to show you how to extract these and put it into text with markdown
# This relies on the code in Question 7 Part B
library(broom)
reg_tidy <- reg %>%
  tidy()

beta_0_hat <- reg_tidy %>% # save this as beta_0_hat
  slice(1) %>% # look only at first row (intercept)
  pull(estimate) %>% # extract the value of the estimate
  round(., 2) # round to 2 decimal places

beta_0_hat # look at it
```

The estimated regression is:

$$
\widehat{\text{agree_pct}_i} = 56.16 + 0.99 \, \text{net_trump_vote}_i
$$

$\hat{\beta_0}$ is `r round(beta_0_hat, 2)`. On the graph, this is where the estimated line crosses the vertical axis. We would predict that for a `net_trump_vote` of 0 (i.e. a 50-50 tie in the district between Clinton & Trump), that district's Member of Congress would vote **56%** of the time with President Trump.

---

### Part B
What is $\hat{\beta_1}$ for this model? What does it mean in the context of our question?

---

<!--ANSWER BELOW HERE-->

```{r}
beta_1_hat <- reg_tidy %>% # save this as beta_0_hat
  slice(2) %>% # look only at second row (net_trump_score)
  pull(estimate) %>% # extract the value of the estimate
  round(., 2) # round to 2 decimal places

beta_1_hat # look at it
```

$\hat{\beta_1}$ is `r round(beta_1_hat, 2)`. This is the estimated slope of the line, and the marginal effect of (a 1 unit change in) $X$ on $Y$.

For every 1 additional point in `net_trump_vote` (i.e. a Trump win by 1 more point), that district's Member of Congress would vote about **1%** more of the time with President Trump.

---

### Part C
What is $R^2$ for this model? What does it mean in the context of our question?

---

<!--ANSWER BELOW HERE-->

```{r}
# this uses the glance command in question 7 part C. 

r_sq <- glance(reg) %>%
  pull(r.squared) %>%
  round(., 2)

r_sq # look at it
```

$R^2$ is `r round(r_sq, 2)`. This means that about 61% of the variation in `agree_pct` is explained by our model.

---

### Part D
What is the $SER$ for this model? What does it mean in the context of our question?

---

<!--ANSWER BELOW HERE-->

```{r}
# this uses the glance command in question 7 part C. 

ser <- glance(reg) %>%
  pull(sigma) %>% 
  round(.,2) # round to 2 decimals

ser # look at it
```

SER $(\hat{\sigma_u})$ is `r round(ser, 2)`. This means that the average prediction error (distance from any data point to the line) is 25 percentage points.

---

## Question 7
We can look at regression outputs in a tidier way, with the `broom` package. 

### Part A
Install (if you have not yet done so) and load the `broom` package.

---

<!--ANSWER BELOW HERE-->

```{r}
# install.packages("broom")
library(broom)
```

---

### Part B
Run the function `tidy()` on your regression object (saved in question 6). Save this result as an object and then look at it.

---

<!--ANSWER BELOW HERE-->

```{r}
reg_tidy <- reg %>%
  tidy()

reg_tidy
```

---

### Part C
Run the `glance()` function on your original regression object. What does it show you? Find $R^2$ and the SER and confirm they are the same from the Base R `lm` output.

---

<!--ANSWER BELOW HERE-->

```{r}
reg %>%
  glance()
```

It shows you summary statistics of the regression, particularly its goodness of fit.

- `r.squared` is the $R^2$ value
- `sigma` is the $SER \; (\hat{\sigma_u})$

That's all we need for now.

---

### Part D
Now run the `augment()` function on your original regression object, and save this as an object. Look at it. What does it show you?

---

<!--ANSWER BELOW HERE-->

```{r}
reg_aug <- reg %>%
  augment()

reg_aug
```

It takes the original data points for `Y` and `X` and adds new variables with values for those observations:
- `.fitted` is $\hat{Y_i|X}$, the predicted value for a specific `net_trump_vote`
- `.resid` is $\hat{u_i}$, the residual or error for a specific `net_trump_vote`
$$\begin{align*}
\hat{u_i}&=Y_i-\hat{Y_i}\\
.resid &= agree\text{_}pct - .fitted\\
\end{align*}$$

That's all we need right now.

---

## Question 8

Let's use our `broom` results to calculate the goodness of fit statistics you found in question 6 to confirm.

Calculate $R^2$ as $\frac{ESS}{TSS}$ by taking the variance of $\widehat{\text{agree_pct}_i}$ (`.fitted` in the `augment`ed object you made in Question 6D) over the variance of $\text{agree_pct}$.

Alternately, you can calculate $R^2$ as $1-\frac{SSE}{TSS}$ by taking 1 minus sum of squared $\hat{u_i}$ (`.resid` in that same `augment`ed object) over the variance of $\text{agree_pct}$.

**Optional**: If you really want to be fancy, make your own function to calculate the sum of squares of $\hat{Y}$ and $Y_i$ (instead of variance), as I did, with:

```{r, eval = F}
sum_sq = function(x){sum((x - mean(x))^2)}
```

and then running this function on `agree_pct` and `.fitted`.

---

<!--ANSWER BELOW HERE-->

```{r}
# calculate R^2 as ratio of variances of predicted to actual Y values
reg_aug %>%
  summarize(var_y_hat = var(.fitted),
            var_y = var(agree_pct),
            R_sq = var_y_hat/var_y)

# using my custom sum of squares function
sum_sq = function(x){sum((x - mean(x))^2)}

# R^2 = ESS/TSS
reg_aug %>%
  summarize(ESS = sum_sq(.fitted),
            TSS = sum_sq(agree_pct),
            R_sq = ESS/TSS)

# R^2 = 1 - (SSE/TSS)
reg_aug %>%
  summarize(SSE = sum(.resid^2),
            TSS = sum_sq(agree_pct),
            R_sq = 1-(SSE/TSS))

# and of course, find R^2 by just squaring correlation coefficient
congress %>%
  summarize(correlation = cor(net_trump_vote, agree_pct),
            R_sq = correlation^2)
```
---

## Question 9

Now let's try presenting your results in a regression table. Install and load the `huxtable` package, and run the `huxreg()` command. Your main input is your regression object you saved in Question 6. Feel free to customize the output of this table (see the slides).

---

<!--ANSWER BELOW HERE-->

```{r}
#install.packages("huxtable")
library(huxtable)
# basic
huxreg(reg)

# some customization:
huxreg("Agree with President (Proportion)" = reg,
       coefs = c("Intercept" = "(Intercept)",
                 "Net Trump Vote" = "net_trump_vote"),
       statistics = c("n" = "nobs",
                      "R-squared" = "r.squared",
                      "SER" = "sigma"),
       number_format = 4)
```

---

# Regression Diagnostics

## Question 10
Now let's start looking at the residuals of the regression. 

### Part A
Take the `augment`ed regression object from Question 7D and use it as the source of your data to create a histogram with `ggplot()`, setting `aes(x = .resid)`. Does it look roughly normal?

---

<!--ANSWER BELOW HERE-->

```{r}
ggplot(data = reg_aug)+
  aes(x = .resid)+
  geom_histogram(color = "white")+
  theme_classic()
```

---

### Part B

Take the `augment`ed regression object and make a residual plot, which is a scatterplot where `x` is the normal `x` variable, and `y` is the `.resid`. Feel free to add a horizontal line at 0 with `geom_hline(yintercept = 0)` as an additional layer. 

---

<!--ANSWER BELOW HERE-->

```{r}
ggplot(data = reg_aug)+
  aes(x = net_trump_vote, y = .resid)+
  geom_point()+
  geom_hline(yintercept = 0, color = "red")+
  theme_classic()
```

---

## Question 11
Now let's check for heteroskedasticity.

### Part A

Looking at the scatterplot and residual plots in Questions 3 and 7B, do you think the errors are heteroskedastic or homoskedastic?

---

<!--ANSWER BELOW HERE-->

It does seem like it would be, looking at the residual plot, since there are clear downward-moving clusters of points that are at times above the line, then below the line, then above and below the line. 

---

### Part B

Install and load the `lmtest` package and run `bptest()` on your saved `lm` object from Question 6. According to the test, is the data heteroskedastic or homoskedastic?

---

<!--ANSWER BELOW HERE-->

```{r}
# install.packages("lmtest")
library(lmtest)
bptest(reg)
```

Since the $p$-value was less than 0.05, we can reject the null hypothesis $H_0$ (that the errors are homoskedastic), and conclude that the errors are heteroskedastic. We will need to fix them if we want accurate standard errors.

---

### Part C

Now let's make some heteroskedasticity-robust standard errors. Install and load the `estimatr` package and use the `lm_robust()` command (instead of the `lm()` command) to run a new regression (and save it). Make sure you add `se_type = "stata"` inside the command to calculate robust SEs (in the same way that the Stata software does...long story). Look at it. What changes?

---

<!--ANSWER BELOW HERE-->

```{r}
#install.packages("estimatr")
library(estimatr)

reg_rse <- lm_robust(agree_pct ~ net_trump_vote, data = congress, se_type="stata")
reg_rse
```

The standard errors on both estimates $(\hat{\beta_0}$ and $\hat{\beta_1})$ change, but the estimates themselves do not change! 

Note `t values` and `Pr(>|t|)` will change, and this command adds confidence intervals (`CI`) and degrees of freedom for $t$, `DF`, but we have not covered any of these yet!

---

### Part D

Now let's see this in a nice regression table. Use `huxreg()` again, but add both your original regression and your regression saved in part C. Notice any changes?

---

<!--ANSWER BELOW HERE-->

```{r}
huxreg("Original" = reg,
       "Robust SEs" = reg_rse,
       number_format = 6) # need to see more decimal places!
```

Note that the standard errors are too small to register anything within 3 decimal places (the default). If we were to make a true percent variable out of 100% instead of out of 1 (as I have you do in Question 13), we would see more of a difference. Look carefully, the standard error on `net_trump_vote` is 0.000192 (from Question 5), and the robust standard error is 0.000149 from Part C. 

---

## Question 12

Now let's check for outliers. 

### Part A

Just looking at the scatterplot in Question 3, do you see any outliers?

---

<!--ANSWER BELOW HERE-->

It looks like there might be one - for the Member whose district's Net vote was somewhere around $-60$ and s/he agrees with the President about $0.6$.

---

### Part B

Install and load the `car` package. Run the `outlierTest` command on your regression object. Does it detect any outliers?

---

<!--ANSWER BELOW HERE-->

```{r}
# install.packages("car")
library(car)
outlierTest(reg)
```

Yes, surprisingly it's not the point that looks like it stands out on the graph (middle-left), it's a different point.

---

### Part C

Look in your original data to match this outlier with an observation. Hint: use the `slice()` command, as the outlier test gave you an observation (row) number!

---

<!--ANSWER BELOW HERE-->

```{r}
congress %>%
  slice(1708)
```

---

## Question 13

(**Optional**: Flexing your tidyverse skills)

This data is still a bit messy. Let's check your `tidyverse` skills again! For example, we'd probably like to plot our scatterplots with colors for Republican and Democratic party. Or plot by the House and the Senate.

### Part A

First, the variable `congress` (session of Congress) seems a bit off. Get a `count()` of `congress`.

---

<!--ANSWER BELOW HERE-->

```{r}
congress %>%
  count(congress)
```

---

### Part B

Let's get rid of the `0` values for `congress` (someone made a mistake coding this, probably).

---

<!--ANSWER BELOW HERE-->

```{r}
congress_tidy <- congress %>%
  filter(congress != 0)
```

---

### Part C

The variable `party` is also quite a mess. `count()` by `party` to see. Then let's `mutate` a variable to make a better measure of political party - just `"Republican"`, `"Democrat"`, and `"Independent"`. Try doing this with the `case_when()` command (as your `mutate` formula).

The syntax for `case_when()` is to have a series of `condition ~ "Outcome"`, separated by commas. For example, one condition is to assign both `"Democrat"` and `"D"` to `"Democrat"`, as in `party %in% c("Democrat", "D") ~ "Democrat"`. You could also do this with a few `ifelse()` commands, but that's a bit more awkward.] When you're done `count()` by your new party variable to make sure it worked.

---

<!--ANSWER BELOW HERE-->

```{r}
# a mess!
congress %>%
  count(party)

# make it tidier
congress_tidy <- congress_tidy %>%
  mutate(pol_party = case_when(
    party %in% c("Democrat", "D") ~ "Democrat",
    party %in% c("Republican", "R") ~ "Republican",
    party %in% c("Independent", "I") ~ "Independent"
  ))

congress_tidy %>%
  count(pol_party)
```

---

### Part D
Now plot a scatterplot (same as Question 4) and set `color` to your party variable. Notice `R` uses its own default colors, which don't match to the actual colors these political parties use! Make a vector where you define the party colors as follows: 

```{r, eval=F}
party_colors <- c("Democrat" = "blue",
                  "Republican" = "red",
                  "Independent" = "gray")
```

Then, run your plot again, adding the following layer to customize the colors `scale_colour_manual("Parties", values = party_colors)`. `"Parties"` is the title that will show up on the legend, feel free to edit it, or remove the legend with another layer `+guides(color = F)`.

---

<!--ANSWER BELOW HERE-->

```{r}
party_colors <- c("Democrat" = "blue",
                  "Republican" = "red",
                  "Independent" = "gray")

p <- ggplot(data = congress_tidy)+
  aes(x = net_trump_vote, y = agree_pct)+
  geom_point(aes(color = pol_party))+
  geom_smooth(method = "lm", color = "black")+
  scale_colour_manual("Parties", values = party_colors)+
  theme_light()
p
```

---

### Part E

Now facet your scatterplot by `chamber` by adding a layer: `facet_wrap(~chamber)`.

---

<!--ANSWER BELOW HERE-->

```{r}
p + facet_wrap(~chamber)

# just for kicks
p+facet_grid(chamber~pol_party)

```

---
